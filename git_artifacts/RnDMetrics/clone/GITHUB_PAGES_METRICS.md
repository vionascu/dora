# Evidence-Backed Metrics Dashboard on GitHub Pages

Your evidence-backed metrics system is now set up to automatically collect metrics and deploy to GitHub Pages.

## ğŸš€ Quick Start

### Access the Dashboard
After metrics collection completes, your dashboard is available at:

**ğŸ“Š Main Dashboard:** https://vionascu.github.io/RnDMetrics/

This link will have:
- Real-time metrics data from your repositories
- Complete evidence trails for every metric
- Professional glassmorphism UI design
- Links to methodology documentation

### Manual Trigger Metrics Collection

To run metrics collection manually:

1. Go to: https://github.com/vionascu/RnDMetrics/actions
2. Click **"Collect Metrics & Deploy Dashboard"** workflow
3. Click **"Run workflow"** button
4. Select branch: **main**
5. Click **"Run workflow"**
6. Wait for workflow to complete (5-10 minutes)
7. Dashboard updates automatically at: https://vionascu.github.io/RnDMetrics/

### Automatic Schedule

Metrics are collected automatically:
- **Frequency:** Daily at 2 AM UTC
- **Time Range:** Last 30 days
- **Next Run:** Check GitHub Actions tab

To modify schedule, edit [.github/workflows/metrics.yml](.github/workflows/metrics.yml):
```yaml
schedule:
  - cron: '0 2 * * *'  # Change this line
```

## ğŸ“Š What Gets Deployed

### Dashboard HTML
- **Location:** `public/index.html`
- **URL:** https://vionascu.github.io/RnDMetrics/
- Generated from `build_dashboard.sh`
- Shows all metrics with evidence trails

### Metrics Data
- **Manifest:** `public/data/manifest.json` - Complete evidence trail
- **Raw Metrics:** `public/data/*_count.json`, `*_stats.json`, etc.
- **Derived Metrics:** `public/data/*_derived.json` - Normalized metrics

### Documentation
- **Methodology:** `public/docs/METHODOLOGY.md` - Formulas and calculations
- **System Guide:** `public/README_METRICS_SYSTEM.md` - How the system works

## ğŸ”„ Workflow Pipeline

```
1. GitHub Actions Triggers (Daily at 2 AM UTC)
         â†“
2. Collect Metrics (collect_metrics.py)
   â”œâ”€â”€ Git: commits, LOC changes
   â”œâ”€â”€ Tests: JUnit XML parsing
   â”œâ”€â”€ Coverage: Jacoco/Cobertura/LCOV
   â””â”€â”€ Docs: Language-specific scanning
         â†“
3. Compute Derived Metrics (compute_derived.py)
   â”œâ”€â”€ Activity: commits/day
   â”œâ”€â”€ Quality: pass rates, coverage adequacy
   â””â”€â”€ Velocity: churn ratio, files/commit
         â†“
4. Validate Quality Gates (quality_gate.py)
   â”œâ”€â”€ Evidence Completeness âœ“
   â”œâ”€â”€ Sanity Checks âœ“
   â””â”€â”€ Determinism Validation
         â†“
5. Build Dashboard (build_dashboard.sh)
   â””â”€â”€ Generate HTML from metrics
         â†“
6. Deploy to GitHub Pages
   â””â”€â”€ Available at: https://vionascu.github.io/RnDMetrics/
```

## ğŸ“ Output Structure

```
artifacts/
â”œâ”€â”€ raw/                           # Raw collected data
â”‚   â”œâ”€â”€ TrailEquip_commits_count.json
â”‚   â”œâ”€â”€ TrailEquip_diffs_stats.json
â”‚   â”œâ”€â”€ TrailWaze_tests_summary.json
â”‚   â”œâ”€â”€ TrailWaze_coverage_summary.json
â”‚   â””â”€â”€ RnDMetrics_docs_coverage.json
â”œâ”€â”€ derived/                       # Computed normalized metrics
â”‚   â”œâ”€â”€ activity_derived.json     # commits_per_day
â”‚   â”œâ”€â”€ quality_derived.json      # pass rates, coverage
â”‚   â”œâ”€â”€ velocity_derived.json     # churn, LOC, files/commit
â”‚   â””â”€â”€ derived_manifest.json
â””â”€â”€ manifest.json                 # Complete evidence trail
```

## ğŸ”’ Evidence & Reproducibility

Every metric includes complete evidence:

```json
{
  "metric_id": "TrailEquip/commits.count",
  "source": {"type": "git"},
  "commands": ["git log --since=2026-01-01 --until=2026-01-31 --format=%H"],
  "raw_file": "artifacts/raw/TrailEquip_commits_count.json",
  "raw_file_hash": "abc123...",
  "collected_at": "2026-01-31T10:30:00+00:00"
}
```

To verify any metric manually:

```bash
# 1. Find metric in manifest
cat artifacts/manifest.json | jq '.evidence_map.["TrailEquip/commits.count"]'

# 2. Get the command
"git log --since=2026-01-01 --until=2026-01-31 --format=%H"

# 3. Run it
cd ../TrailEquip
git log --since=2026-01-01 --until=2026-01-31 --format=%H | wc -l

# 4. Should match reported value âœ“
```

## ğŸ¯ Metrics at a Glance

### Git Metrics
- `commits.count` - Total commits in range
- `diffs.loc_added` - Lines added
- `diffs.loc_deleted` - Lines deleted
- `diffs.files_changed` - Files modified

### Quality Metrics
- `tests.pass_rate` - Test success percentage
- `coverage.line_percent` - Line coverage %
- `docs.coverage_percent` - Documentation %

### Velocity Metrics
- `activity.commits_per_day` - Commit frequency
- `velocity.loc_net` - Net code change
- `velocity.churn_ratio` - Refactoring ratio
- `velocity.files_per_commit` - Commit scope

## ğŸ“– Documentation

- **[METHODOLOGY.md](Documents/METHODOLOGY.md)** - Complete formula reference
- **[README_METRICS_SYSTEM.md](README_METRICS_SYSTEM.md)** - System overview
- **[config/repos.yaml](config/repos.yaml)** - Repository configuration

## ğŸ§ª Local Testing

To test metrics collection locally:

```bash
# Collect metrics
./run_metrics.sh --range last_30_days

# Build dashboard
./build_dashboard.sh

# View dashboard
open public/index.html

# Run tests
./run_tests.sh
```

## ğŸ”§ Configuration

### Time Ranges Available
- `last_30_days` - Past 30 days (default)
- `last_90_days` - Past 90 days
- `ytd` - Year to date
- `all_2024` - All of 2024
- `all_2025` - All of 2025
- `custom --from DATE --to DATE` - Custom range

### Modify Collection Schedule
Edit [.github/workflows/metrics.yml](.github/workflows/metrics.yml):

```yaml
schedule:
  - cron: '0 2 * * *'  # Daily at 2 AM UTC
  # Every 6 hours: cron: '0 */6 * * *'
  # Every 4 hours: cron: '0 */4 * * *'
  # Weekly Monday 9 AM: cron: '0 9 * * 1'
```

### Add CI Artifacts

To enable test/coverage metrics:

1. Configure `ci_artifacts_path` in [config/repos.yaml](config/repos.yaml)
2. Ensure CI publishes JUnit XML and coverage reports
3. Re-run workflow: metrics will auto-detect artifacts

```yaml
repos:
  - name: TrailEquip
    ci_artifacts_path: ../ci_artifacts/TrailEquip  # Point to CI outputs
```

## ğŸš¨ Troubleshooting

### Dashboard shows 404
- Check GitHub Pages is enabled:
  - Settings â†’ Pages â†’ Source: "Deploy from GitHub Actions"
- Wait 2-3 minutes after workflow completes
- Hard refresh: Cmd+Shift+R (Mac) or Ctrl+Shift+R (Windows)

### Workflow shows failed status
1. Go to: https://github.com/vionascu/RnDMetrics/actions
2. Click failed workflow run
3. Expand log section to see errors
4. Common issues:
   - Missing repos (update config/repos.yaml)
   - Missing pyyaml (auto-installed)
   - Git permission issues

### No metrics collected
- Check repo paths in [config/repos.yaml](config/repos.yaml)
- Verify repos have git history in the date range
- Ensure repos are accessible on local machine

## ğŸ“Š Dashboard URL

Your dashboard is live at:

### ğŸ¯ **https://vionascu.github.io/RnDMetrics/**

Share this link with your team!

## âœ¨ Features

âœ… Real-time metrics from your repositories
âœ… Complete evidence trail for every metric
âœ… Professional UI with glassmorphism design
âœ… Fully transparent calculations
âœ… Automatic daily updates
âœ… Zero cost (uses GitHub Actions free tier)
âœ… No servers to manage
âœ… 100% version controlled

## ğŸ“ Support

For questions:
- See [METHODOLOGY.md](Documents/METHODOLOGY.md) for metric definitions
- Check [README_METRICS_SYSTEM.md](README_METRICS_SYSTEM.md) for system overview
- Review workflow logs: https://github.com/vionascu/RnDMetrics/actions

---

**Status:** âœ… Production Ready

**Dashboard:** https://vionascu.github.io/RnDMetrics/

**Last Updated:** January 31, 2026
